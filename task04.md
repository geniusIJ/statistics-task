linear regression步骤： 
1.导入数据 
2.将数据分为训练集合测试集 
（linear regression 分为x_train, x_text, y_train, y_test） 
3.导入线性回归算法 
利用训练集计算出模型参数 
4.模型检验 
利用测试集测试真实值和预测值的差异 
（用x_test计算出y_predict，与y_test做比较，计算误差） 
5.打印结果

求梯度计算得到J(θ)最小值 
过程解释： 
1.Xθ-Y是一个列向量。平方和可以写成向量的转置乘以他本身。 

2.A是对称矩阵时∇θ(θTAθ)=2Aθ 

3.用python 语言表示最终的结果就是
import numpy as np
#调用numpy里的求逆函数
X_=np.linalg.inv(X.T.dot(X))
#X.T表示转置，X.dot(Y)表示矩阵相乘
theta=X.dot(X.T).dot(Y)
import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets

class LinearRegression():
    def __init__(self):#新建变量
        self.w = None

    def fit(self, X, y):#训练集的拟合
        X = np.insert(X, 0, 1, axis=1)#增加一个维度
        print (X.shape)        
        X_ = np.linalg.inv(X.T.dot(X))#公式求解
        self.w = X_.dot(X.T).dot(y)

    def predict(self, X):#测试集的测试反馈
        #h(theta)=theta.T.dot(X)
        # Insert constant ones for bias weights
        X = np.insert(X, 0, 1, axis=1)
        y_pred = X.dot(self.w)
        return y_pred

def mean_squared_error(y_true, y_pred):
#真实数据与预测数据之间的差值（平方平均）
    mse = np.mean(np.power(y_true - y_pred, 2))
    return mse

def main():
    #第一步：导入数据
    # Load the diabetes dataset
    diabetes = datasets.load_diabetes()

    # Use only one feature
    X = diabetes.data[:, np.newaxis, 2]
    print (X.shape)

    #第二步：将数据分为训练集以及测试集
    # Split the data into training/testing sets
    x_train, x_test = X[:-20], X[-20:]

    # Split the targets into training/testing sets
    y_train, y_test = diabetes.target[:-20], diabetes.target[-20:]

    #第三步：导入线性回归类（之前定义的）
    clf = LinearRegression()
    clf.fit(x_train, y_train)#训练
    y_pred = clf.predict(x_test)#测试

    #第四步：测试误差计算（需要引入一个函数）
    # Print the mean squared error
    print ("Mean Squared Error:", mean_squared_error(y_test, y_pred))

    #matplotlib可视化输出
    # Plot the results
    plt.scatter(x_test[:,0], y_test,  color='black')#散点输出
    plt.plot(x_test[:,0], y_pred, color='blue', linewidth=3)#预测输出
    plt.show()
    参考资料：https://blog.csdn.net/TigerTai98/article/details/72956331
    
    一、T检验
1.1 样本均值比较T检验的使用前提
正态性；（单样本、独立样本、配对样本T检验都需要）
连续变量；（单样本、独立样本、配对样本T检验都需要）
独立性；（独立样本T检验要求）
方差齐性；（独立样本T检验要求）
1.2 样本均值比较T检验的适用场景
单样本T检验（比较样本均数和总体均数）； 
操作：打开 分析—比较均值—单样本t检验

要求：正态性（可以用K-S检验法，在SPSS中的“分析”–“非参数检验”—“单样本”中；或者直接根据直方图、P-P图，Q-Q图来观察或根据偏度峰度法来分析）

说明：由中心极限定理可知，即使原数据不符合正态分布，只要样本量足够大时样本均数分布仍然是正态的。只要数据不是强烈的偏正态，没有明显的极端值，一般而言单样本t检验都是可以使用的，分析结果都是稳定的。

独立样本T检验（比较成组设计的两个样本）； 
操作：打开 分析—比较均值—独立样本t检验 
我们输入数据的时候，两个样本的数据是要在一列变量里的，另外还有一列二分类变量为这列因变量做标注。

要求：独立性、正态性（对正态性有耐受性）、方差齐性（影响大，检验更有必要，使用Levene’s检验，两样本T检验中提供Levene’s检验，如需更详细的检验结果可在“分析”–“描述统计”–“探索”中进行）

说明：各样本相互独立，且均来自于正态分布的样本，各样本所在总体的方差相等；

* 疑问：独立性怎么检验？有些数据可以根据现实环境判断；*

配对样本T检验（如用药前和用药后的两个人群的样本、同一样品用两种方法的比较） 
操作：打开 分析—比较均值—配对样本t检验

要求：正态性（配对样本等价于单样本T检验，检验的是两个样本对应的差值，初始假设为差值等于0）

二、单因素方差分析
2.1 单因素方差分析的基本思想
基本思想：变异分解，总变异=随机变异+处理因素导致的变异，又可以分解为总变异=组内变异+组间变异，F=组间变异/组内变异，F的值越大，处理因素的影响越大。
2.2 单因素方差分析的使用前提
独立性：不满足独立性会有很大的影响，因为信息存在“重叠”的部分 
疑问：在哪儿可以验证？卡方检验？卡方检验检验的是两个分类变量
正态性：对正态性的要求是稳健的
方差齐性：检验方法除了Levene’s检验，还可以有其他的检验方法：Bartleet法（比较各组方差的加权算数平均数和几何均数）、Hartley法（样本量相同时使用）、Cochran法（样本量相同时使用）。 
方差分析对变量的类型有要求吗？应该分析的都是连续变量
2.3 单因素方法分析的使用前提不满足时变换方法
对数变换、平方根变换、平方根反正弦变换、平方变换、倒数变换、Box-Cox变换（分段函数）
2.4 单因素方差分析的适用场景
T检验只能检验两组样本的均数差，多组样本的时候就需采用方差分析；

操作：打开分析—比较均值—均值 进行预分析，可以大致看出各均值是否相同，方差是否齐性；再进行 打开 分析—比较均值—单因素anova；

适用场景：均数间的多重比较（全部两两比较）、各组均数的精细比较（可以指定要比较的两个组，通过设定系数）、组间均数的趋势检验（为了利用分组变量中体现出的次序信息，目的不是为了拟合线性或非线性的模型，而是希望知道因素的水平改变时均数的变化趋势）

2.5 方差分析结束后如均值不同可进行两两比较（事前比较、事后比较）
LSD法：用于事先计划好的比较，最灵敏；检验水准没有校正，每次都是α 
Sidak法：第二灵敏； 
Bonferroni法：用于事先计划好的比较，第三灵敏； 
Scheffe法：多用样本含量不等的情况，第四灵敏； 
Dunnett法：常用于多个实验组和一个对照组的比较，第五灵敏；

寻找同质亚组的检验方法： 
S-N-K法：将所有样本分为多个子集； 
Tukey法：任意两组比较，要求样本含量相同，MEER不超过α； 
Duncan法：与SNK法类似；

备注： 
CER：每进行一次比较犯一类错误错误的概率； 
EERC：完全无效假设检验下，做完全部比较犯一类错误的概率； 
MEER：部分或者任何完全假设下，犯一类错误的最大概率值，即最大实验误差率。

疑问：单因素方差分析的事前检验和事后检验有什么区别，为什么结果不同？？

三、非参数检验
3.1 非参数检验的基本思想
非参数检验的意思是指整个推断过程和结论均和原总体参数无关，而不是不利用参数
3.2 非参数检验的优势
稳健性；
对数据的测量尺度、数据类型无约束；
适用于小样本、无分布样本、数据污染样本、混杂样本等；
3.3 非参数检验使用前提
有序、名义变量，这类数据的分布形态一般未知，均值方差等数据无意义；
样本分布未知；
样本数据不满足正态分布，即便是经过变量变换；
方差齐性不满足，即便是经过变量变换；
总体分布正态，连续变量，但样本容量极小，如10以下；
3.2 非参数检验适用情形
单样本非参数检验

K-S检验：针对连续变量，考察是否符合正态分布 
操作：打开–分析–非参数检验–单样本

二项分布检验：针对两分类变量，考察是否符合二项分布 
操作：打开–分析–非参数检验–单样本

游程检验：考察总体的随机性 
操作：打开–分析–非参数检验–单样本
两个独立样本的非参数检验（无效假设为两样本的中心位置是否相等）

Mann-Whitney U检验，两样本秩和检验，应用范围最广；

Kolmogorov-Smirnov Z检验：检验两个样本的累积频数分布曲线，判断两个样本的分布是否相同；

Moses Extreme Reactions 检验：Moses极端反应检验，单侧检验

Wald-Wolfowitz Runs 检验：单侧检验，无论是集中趋势、离散趋势、偏度的波动情况都能检测出来，如果只是检查中心位置，最好不用，检验两样本是否来自同样的分布；

操作：打开 分析—非参数检验—独立样本

多个独立样本的非参数检验

Kruskal-Wallis H检验（类似Wilcoxon符号秩检验，两样本在多样本上的推广）

中位数检验

Jonckheere-Terpstra检验：对连续变量和有序分类资料都使用，分组变量为有序分类资料时，检验效能要高于Kruskal-Wallis H检验

操作：打开 分析—非参数检验—独立样本

两个配对样本（求出差值，查看中位数是否为0，目的就是为了检验均值是否相等）

sign符号检验：只利用了符号信息，差值是否一半为正一半为负；

Wilcoxon符号秩检验：利用了符号和差值的大小顺序（符号+秩序）

操作：打开 分析—非参数检验—相关样本
多个相关样本非参数检验

Friedman 检验：基本思想是同区组的处理值和计算的秩比较才有意义，还附带齐性子集结果给出了准确的两两比较信息；

Kendall协和系数检验：为了检验各组评价是否一致，Friedman检验只能说明尚不能认为有差异，但是无法评判一致性，Kendall方法针对连续变量，

Cochran检验：有些评价只能用是否、好坏等二元数据来判断，Cochran只适用于二分类变量，用Kendall方法会有很多的打结现象。

操作：打开 分析–非参数检验–相关样本

通用方法—秩变换分析方法

前面有关秩的分析方法其实都是秩变换方法的不同应用，分析方法中可以直接将秩求出后再进行分析。

操作：转换 — 个案排秩（也可以指定生成符合正态分布的秩）

四、卡方检验
4.1 卡方检验的基本思想
以卡方分布为基础，计算观察值和期望值之间的偏离程度；
4.2 卡方检验的使用前提
最小期望频数均大于1
至少4/5的单元格期望频数大于5
计算时如果单元格期望频数小于5要和其他种类合并
样本观察值量超过50
4.3 卡方检验的使用目的
考察无序分类变量各水平在两组或多组间的分布是否一致；
检验某个连续变量的分布是否和理论分布一致；
分类变量的概率是否等于指定概率；
检验两个分类变量是否独立；
检验控制了其中几个因素后，剩余的两个分类变量是否独立；
检验两种方法的结果是否一致；
4.4 卡方检验的适用场景
单样本卡方检验 
操作： 打开 分析–非参数检验–单样本

两样本卡方检验 
操作： 打开 分析–描述统计–交叉表

两分类变量间关联程度的度量：定性描述两个分类变量是否存在关联（更为详细的可以根据相关分析） 
操作： 打开 分析–描述统计–交叉表

Kappa一致性检验（用于配对样本，如两个人针对一个事物的评价） 
用于配对样本的检验，Kappa检验的结果是两个人的评价是否是相关的 
操作： 打开 分析–描述统计–交叉表

Mcnemar 配对卡方检验 
Kappa检验只能看出两者是否有关联，但是不能判断是否一致，Mcnemar 配对卡方检验就可以解决两者是否一致的问题 
操作： 打开 分析–描述统计–交叉表

分层卡方检验 
可以控制一个因素，如收入对车辆购买率的影响，可以将城市作为分层因素，从而可以得到更准确的结果，但是SPSS中只能进行两分类变量的检验，不能进行多分类的检验，且分层因素和要分析的因素之间如果存在交互关系也不能进行检验。 
操作： 打开 分析–描述统计–交叉表

4.5 备注
相对危险度（RR） 
RR=试验人群反应阳性的概率/对照组人群反应阳性的概率 
RR=1，说明试验因素反应阳性没有关联 
RR＜1，说明试验因素导致反应阳性的发生率降低 
RR＞1，说明试验因素导致反应阳性的发生率升高

优势比（OR） 
OR=（反应阳性组中实验因素阳性人数/反应阳性组中实验因素阴性人数）/（反应阴性组中实验因素阳性人数/反应阴性组中实验因素阴性人数） 
OR＞1，说明该试验因素更容易导致实验结果为阳性
参考资料：https://blog.csdn.net/youngmiffy/article/details/53490495 
